import os
os.environ["HF_HOME"] = "E:/huggingface_cache"
import datetime
import torch
from diffusers import StableDiffusionXLPipeline

# === é…ç½®åŒºï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰===
HF_CACHE_DIR = "E:/huggingface_cache"
OUTPUT_DIR = "E:\StableDiffusion\outputs\PICTURE"
LORA_PATH = "E:\StableDiffusion\LORA\output\GHIBLI.safetensors"

# æç¤ºè¯ï¼ˆå»ºè®®ç”¨é£æ™¯ç±»ï¼‰
PROMPT = "ghibli style, studio ghibli anime, " + \
         "a serene mountain landscape with a crystal-clear lake, pine trees, morning mist, golden hour"
NEGATIVE_PROMPT = "blurry, low quality, text, watermark, cartoon, people, buildings"

SEED = 42
HEIGHT = 1024
WIDTH = 1024
STEPS = 30
GUIDANCE_SCALE = 7.5

# === åˆå§‹åŒ– ===
os.makedirs(OUTPUT_DIR, exist_ok=True)
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

print("ğŸ”„ æ­£åœ¨åŠ è½½ SDXL åŸºç¡€æ¨¡å‹...")
pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True,
    cache_dir=HF_CACHE_DIR
)
pipe = pipe.to("cuda")
pipe.enable_xformers_memory_efficient_attention()
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼")

generator = torch.Generator(device="cuda").manual_seed(SEED)

#=== 1. ç”ŸæˆåŸå§‹å›¾åƒï¼ˆæ—  LoRAï¼‰===
print("ğŸ–¼ï¸ ç”ŸæˆåŸå§‹å›¾åƒï¼ˆæ—  LoRAï¼‰...")
image_original = pipe(
    prompt=PROMPT,
    negative_prompt=NEGATIVE_PROMPT,
    height=HEIGHT,
    width=WIDTH,
    num_inference_steps=STEPS,
    guidance_scale=GUIDANCE_SCALE,
    generator=generator,
).images[0]

path_original = os.path.join(OUTPUT_DIR, f"sdxl_{timestamp}_original.png")
image_original.save(path_original)
print(f"âœ… åŸå§‹å›¾åƒå·²ä¿å­˜: {path_original}")

# === 2. æ³¨å…¥ LoRA å¹¶ç”Ÿæˆé£æ ¼åŒ–å›¾åƒ ===
print(f"ğŸ”— æ­£åœ¨åŠ è½½ LoRA: {LORA_PATH}")
pipe.load_lora_weights(LORA_PATH)  # â­ å…³é”®ï¼šæ³¨å…¥ LoRA
pipe.fuse_lora(lora_scale=2.0)  # â­ èåˆ LoRA æƒé‡ï¼ˆæå‡æ¨ç†é€Ÿåº¦ï¼‰
print("Active adapters:", pipe.get_active_adapters())

print("ğŸ¨ ç”Ÿæˆ LoRA é£æ ¼å›¾åƒ...")
# æ³¨æ„ï¼šé‡ç½® generator seed ä¿è¯å¯æ¯”æ€§ï¼
generator = torch.Generator(device="cuda").manual_seed(SEED)
image_lora = pipe(
    prompt=PROMPT+", ghibli style",
    negative_prompt=NEGATIVE_PROMPT,
    height=HEIGHT,
    width=WIDTH,
    num_inference_steps=STEPS,
    guidance_scale=GUIDANCE_SCALE,
    generator=generator,
).images[0]

path_lora = os.path.join(OUTPUT_DIR, f"sdxl_{timestamp}_lora.png")
image_lora.save(path_lora)
print(f"âœ… LoRA å›¾åƒå·²ä¿å­˜: {path_lora}")

# === å¯é€‰ï¼šå¸è½½ LoRAï¼ˆå¦‚æœåç»­è¿˜è¦ç”¨åŸå§‹æ¨¡å‹ï¼‰===
pipe.unfuse_lora()
pipe.unload_lora_weights()

print("\nğŸ‰ å¯¹æ¯”å®éªŒå®Œæˆï¼è¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶å¤¹ä¸­çš„ä¸¤å¼ å›¾ç‰‡ã€‚")